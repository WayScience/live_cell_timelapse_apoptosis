{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform feature selection on normalized data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gc\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from pycytominer import feature_select\n",
    "from pycytominer.cyto_utils import output\n",
    "\n",
    "try:\n",
    "    cfg = get_ipython().config\n",
    "    in_notebook = True\n",
    "except NameError:\n",
    "    in_notebook = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not in_notebook:\n",
    "    print(\"Running as script\")\n",
    "    argparser = argparse.ArgumentParser()\n",
    "    argparser.add_argument(\"--num_of_features\", type=int, default=1000)\n",
    "    argparser.add_argument(\"--num_of_cells_per_well\", type=int, default=100)\n",
    "    argparser.add_argument(\"--num_of_groups\", type=int, default=50)\n",
    "    argparser.add_argument(\"--num_of_replicates\", type=int, default=4)\n",
    "    args = argparser.parse_args()\n",
    "\n",
    "    num_of_features = args.num_of_features\n",
    "    num_of_cells_per_well = args.num_of_cells_per_well\n",
    "    num_of_groups = args.num_of_groups\n",
    "    num_of_replicates = args.num_of_replicates\n",
    "else:\n",
    "    num_of_features = 3000\n",
    "    num_of_cells_per_well = 1000\n",
    "    num_of_groups = 50\n",
    "    num_of_replicates = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_process = psutil.Process()\n",
    "prior_mem_info = prior_process.memory_info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define operations to be performed on the data\n",
    "# list of operations for feature select function to use on input profile\n",
    "feature_select_ops = [\n",
    "    \"variance_threshold\",\n",
    "    \"blocklist\",\n",
    "    \"drop_na_columns\",\n",
    "    \"correlation_threshold\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a profile for input data for fs\n",
    "\n",
    "\n",
    "def generate_toy_data(\n",
    "    num_of_features: int = 1000,\n",
    "    num_of_cells_per_well: int = 100,\n",
    "    num_of_groups: int = 50,\n",
    "    num_of_replicates: int = 4,\n",
    "    seed: int = 0,\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    num_of_rows_total = num_of_groups * num_of_replicates\n",
    "    output_dict = {\n",
    "        \"Metadata_Well\": [],\n",
    "    }\n",
    "    for group in range(num_of_groups):\n",
    "        for replicate in range(num_of_replicates):\n",
    "            well = f\"{group}_{replicate}\"\n",
    "            output_dict[\"Metadata_Well\"].extend([well] * num_of_cells_per_well)\n",
    "\n",
    "    for feature in range(num_of_features):\n",
    "        feature_name = f\"feature_{feature}\"\n",
    "        output_dict[feature_name] = np.random.normal(\n",
    "            0, 1, num_of_rows_total * num_of_cells_per_well\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(output_dict)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = generate_toy_data(\n",
    "    num_of_features=num_of_features,\n",
    "    num_of_cells_per_well=num_of_cells_per_well,\n",
    "    num_of_groups=num_of_groups,\n",
    "    num_of_replicates=num_of_replicates,\n",
    "    seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = [\"Metadata_Well\"]\n",
    "feature_cols = [x for x in df.columns if x not in metadata_cols]\n",
    "feature_select_df = feature_select(\n",
    "    df,\n",
    "    operation=feature_select_ops,\n",
    "    features=feature_cols,\n",
    ")\n",
    "\n",
    "num_of_features_retained = feature_select_df.shape[1]\n",
    "percent_of_features_retained = num_of_features_retained / df.shape[1] * 100\n",
    "print(f\"Initial shape: {df.shape}, Final shape: {feature_select_df.shape}\")\n",
    "print(f\"Number of features retained: {num_of_features_retained}\")\n",
    "print(f\"Percent of features retained: {percent_of_features_retained:.2f}%\")\n",
    "del df\n",
    "del feature_select_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process = psutil.Process()\n",
    "post_mem_info = post_process.memory_info()\n",
    "\n",
    "print(f\"RSS: {(post_mem_info.rss - prior_mem_info.rss) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"VMS: {(post_mem_info.vms - prior_mem_info.vms) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Shared: {(post_mem_info.shared - prior_mem_info.shared) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Text: {(post_mem_info.text - prior_mem_info.text) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Lib: {(post_mem_info.lib - prior_mem_info.lib) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Data: {(post_mem_info.data - prior_mem_info.data) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Dirty: {(post_mem_info.dirty - prior_mem_info.dirty) / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Total: {(post_mem_info.rss - prior_mem_info.rss) / (1024 ** 2):.2f} MB\")\n",
    "\n",
    "output_dict = {\n",
    "    \"num_of_features\": num_of_features,\n",
    "    \"num_of_cells_per_well\": num_of_cells_per_well,\n",
    "    \"num_of_groups\": num_of_groups,\n",
    "    \"num_of_replicates\": num_of_replicates,\n",
    "    \"num_of_features_retained\": num_of_features_retained,\n",
    "    \"percent_of_features_retained\": percent_of_features_retained,\n",
    "    \"rss_MB\": (post_mem_info.rss - prior_mem_info.rss) / (1024**2),\n",
    "    \"vms_MB\": (post_mem_info.vms - prior_mem_info.vms) / (1024**2),\n",
    "    \"shared_MB\": (post_mem_info.shared - prior_mem_info.shared) / (1024**2),\n",
    "    \"text_MB\": (post_mem_info.text - prior_mem_info.text) / (1024**2),\n",
    "    \"lib_MB\": (post_mem_info.lib - prior_mem_info.lib) / (1024**2),\n",
    "    \"data_MB\": (post_mem_info.data - prior_mem_info.data) / (1024**2),\n",
    "    \"dirty_MB\": (post_mem_info.dirty - prior_mem_info.dirty) / (1024**2),\n",
    "    \"total_MB\": (post_mem_info.rss - prior_mem_info.rss) / (1024**2),\n",
    "}\n",
    "output_df = pd.DataFrame(output_dict, index=[0])\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output to a file\n",
    "output_file_path = pathlib.Path(\n",
    "    f\"../results_of_memory_profiling/{num_of_features}_features_{num_of_cells_per_well}_cells_per_well_{num_of_groups}_groups_{num_of_replicates}_replicates.parquet\"\n",
    ").resolve()\n",
    "output_file_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "output_df.to_parquet(output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellprofiler_timelapse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
